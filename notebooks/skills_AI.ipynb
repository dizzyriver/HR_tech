{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2a5d40bf-9c45-4dd8-a4f8-f0f5335c205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "import json\n",
    "import hashlib\n",
    "from typing import List\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "import torch\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.globals import set_verbose, set_debug\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if os.name == \"nt\":\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "    else:\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available else \"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a26512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_skills_to_job(job,topk,model,write_output=True):\n",
    "\n",
    "    model = SentenceTransformer(model_name,device=get_device())\n",
    "    vector = model.encode(job, show_progress_bar=True)\n",
    "\n",
    "    if model_name == \"WhereIsAI/UAE-Large-V1\":\n",
    "        collection_name=\"skills_2024-02-16_UAE-Large-V1\"\n",
    "    if model_name == \"thenlper/gte-large\":\n",
    "        collection_name=\"skills_2024-02-16_gte-large\"\n",
    "    \n",
    "\n",
    "    qdrant_client = QdrantClient(os.getenv(\"QDRANT_URL\"))\n",
    "    hits = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=vector,\n",
    "        limit=topk\n",
    "        )\n",
    "    top_skills = []\n",
    "    for hit in hits:\n",
    "        top_skills.append({\"job\":job} | {\"skill\":hit.payload['name']} | {\"score\":hit.score})\n",
    "   \n",
    "    top_skills = pd.DataFrame(top_skills)\n",
    "    if write_output:\n",
    "        path = os.path.join(os.getenv(\"DATA\"),\"model_outputs\",f\"\"\"{topk}_skills_for_{job}_{model_name.split(\"/\")[1]}_.csv\"\"\")\n",
    "        print(path)\n",
    "        top_skills.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f24f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_skills(skill, top_k, model, model_name, write_output=True):\n",
    "\n",
    "    vector = model.encode(skill, show_progress_bar=True)\n",
    "\n",
    "    if model_name == \"WhereIsAI/UAE-Large-V1\":\n",
    "        collection_name=\"skills_2024-02-16_UAE-Large-V1\"\n",
    "    if model_name == \"thenlper/gte-large\":\n",
    "        collection_name=\"skills_2024-02-16_gte-large\"\n",
    "    \n",
    "\n",
    "    qdrant_client = QdrantClient(os.getenv(\"QDRANT_URL\"))\n",
    "    hits = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=vector,\n",
    "        limit=top_k\n",
    "        )\n",
    "    top_skills = []\n",
    "    for hit in hits:\n",
    "        #print(f\"\"\"{hit.payload['name']}, {hit.score}\"\"\")\n",
    "        top_skills.append({\"query_skill\":skill} | {\"skill\":hit.payload['name']} | {\"score\":hit.score})\n",
    "   \n",
    "    return top_skills\n",
    "    if write_output:\n",
    "        top_skills = pd.DataFrame(top_skills)\n",
    "        path = os.path.join(os.getenv(\"DATA\"),\"model_outputs\",f\"\"\"{topk}_skills_for_{skill}_{model_name.split(\"/\")[1]}_.csv\"\"\")\n",
    "        print(path)\n",
    "        top_skills.to_csv(path, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_jobs_to_skill(skill,topk,model,write_output=True):\n",
    "\n",
    "    model_name = os.getenv(\"EMBEDDING_MODEL\")\n",
    "    model = SentenceTransformer(model_name,device=get_device())\n",
    "    vector = model.encode(skill, show_progress_bar=True)\n",
    "\n",
    "    if model_name == \"WhereIsAI/UAE-Large-V1\":\n",
    "        collection_name=\"jobs_2024-02-16_UAE-Large-V1\"\n",
    "    if model_name == \"thenlper/gte-large\":\n",
    "        collection_name=\"jobs_2024-02-16_gte-large\"\n",
    "    \n",
    "\n",
    "    qdrant_client = QdrantClient(os.getenv(\"QDRANT_URL\"))\n",
    "    hits = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=vector,\n",
    "        limit=topk\n",
    "        )\n",
    "    top_jobs = []\n",
    "    for hit in hits:\n",
    "        #print(f\"\"\"{hit.payload['name']}, {hit.score}\"\"\")\n",
    "        top_jobs.append({\"skill\":skill} | {\"job\":hit.payload['name']} | {\"score\":hit.score})\n",
    "   \n",
    "    top_jobs = pd.DataFrame(top_jobs)\n",
    "    if write_output:\n",
    "        path = os.path.join(os.getenv(\"DATA\"),\"model_outputs\",f\"\"\"{topk}_jobs_for_{skill}_{model_name.split(\"/\")[1]}_.csv\"\"\")\n",
    "        print(path)\n",
    "        top_jobs.to_csv(path, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e70c1c2c-edce-4611-b400-a24ab86be7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_assesment(skill, scale, prompt_template_fname, llm):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a skill assess its importance to a job\n",
    "    \"\"\"\n",
    "\n",
    "    #first fetch the top n most similar jobs for the skill\n",
    "    model = SentenceTransformer(os.getenv(\"EMBEDDING_MODEL\"),device=get_device())\n",
    "    n = 100\n",
    "    vector = model.encode(skill,show_progress_bar=True)\n",
    "    qdrant_client = QdrantClient(os.getenv(\"QDRANT_URL\"))\n",
    "    hits = qdrant_client.search(\n",
    "        collection_name=\"jobs_2024-02-16_UAE-Large-V1\",\n",
    "        query_vector=vector,\n",
    "        limit=100\n",
    "        )\n",
    "    \n",
    "    response_schemas = []\n",
    "    \n",
    "    question_schema =  ResponseSchema(name=f\"\"\"Assesment\"\"\",\n",
    "                                          description=f\"\"\"Assesment of the importance of skill to the job\n",
    "                                          on a scale of 1 to {scale}\"\"\",\n",
    "                                          type=int\n",
    "                                         )\n",
    "    response_schemas.append(question_schema)\n",
    "    answer_schema =  ResponseSchema(name=f\"\"\"Reasoning\"\"\",\n",
    "                                          description=f\"\"\"Reasoning to support the assesment\"\"\",\n",
    "                                          type=str\n",
    "                                         )\n",
    "    response_schemas.append(answer_schema)\n",
    "\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "    prompt_path = os.path.join(os.getenv(\"PROMPTS\"),prompt_template_fname)\n",
    "    with open(prompt_path,\"r\") as file:\n",
    "        template_string = file.read()\n",
    "    prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "\n",
    "    for hit in hits:\n",
    "        \n",
    "        job = hit.payload[\"name\"]\n",
    "        print(f\"\"\"assesing the importance of skill {skill} for job {job}\"\"\")\n",
    "\n",
    "        message = prompt_template.format_messages(\n",
    "                    skill=skill,\n",
    "                    job=job,\n",
    "                    scale=scale,        \n",
    "                    format_instructions=format_instructions)\n",
    "\n",
    "        response = llm(message)\n",
    "        output_dict = output_parser.parse(response.content)\n",
    "        output_dict[\"job\"] = job\n",
    "        output_dict[\"skill\"] = skill\n",
    "        output_dict[\"similarity\"] = hit.score\n",
    "\n",
    "        print(output_dict)\n",
    "\n",
    "        #if \"/\" in job:\n",
    "            #job.replace('/','_')\n",
    "        try:\n",
    "            path = os.path.join(os.getenv(\"ASSESMENTS\"),f\"\"\"assesment_{skill}_{job}.json\"\"\")\n",
    "            with open(path, \"a\",  encoding='utf-8') as file:\n",
    "                json.dump(output_dict,   file, ensure_ascii=False)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db948d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_catalogues():\n",
    "    file_path = os.path.join(os.getenv(\"DATA\"),\"Lightcast/Skills\",\"skill_catalogue.csv\")\n",
    "    skill_catalogue = pd.read_csv(file_path)\n",
    "    file_path = os.path.join(os.getenv(\"DATA\"),\"Lightcast/Jobs\",\"skill_catalogue.csv\")\n",
    "    job_catalogue = pd.read_csv(file_path)\n",
    "    return skill_catalogue, job_catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0055888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skill_to_assess():\n",
    "    skill_to_assess = pd.DataFrame()\n",
    "    skill_to_assess['job'] = job_catalogue\n",
    "    skill_to_assess['skill'] = skill_catalogue.head(n=1).values[0][0]\n",
    "    return skill_to_assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a9ea8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(jobs, prompt_template_fname, llm):\n",
    "\n",
    "    \"\"\"\n",
    "    Extract skills from job\n",
    "    \"\"\"\n",
    "    #first fetch the top n most similar jobs for the skill\n",
    "    \n",
    "    response_schemas = []\n",
    "    question_schema =  ResponseSchema(name=f\"\"\"Skills\"\"\",\n",
    "                                          description=f\"\"\"The skills from the job description in a python list\"\"\"\n",
    "                                          \n",
    "                                         )\n",
    "    response_schemas.append(question_schema)\n",
    "    answer_schema =  ResponseSchema(name=f\"\"\"Benefits\"\"\",\n",
    "                                          description=f\"\"\"The benefits from the job description in a python list\"\"\"\n",
    "                                         )\n",
    "    response_schemas.append(answer_schema)\n",
    "\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "    prompt_path = os.path.join(os.getenv(\"PROMPTS\"),prompt_template_fname)\n",
    "    with open(prompt_path,\"r\") as file:\n",
    "        template_string = file.read()\n",
    "    prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "\n",
    "    for job in jobs:\n",
    "        \n",
    "        job_description = job[\"description\"]\n",
    "        job_id = job[\"id\"]\n",
    "        print(job_id)\n",
    "\n",
    "        print(f\"\"\"Extracting skills and benefits for job {job_id}\"\"\")\n",
    "\n",
    "        message = prompt_template.format_messages(\n",
    "                    job_description=job_description,\n",
    "                    format_instructions=format_instructions)\n",
    "\n",
    "        response = llm(message)\n",
    "        output_dict = output_parser.parse(response.content)\n",
    "        output_dict[\"id\"] = job_id\n",
    "        print(output_dict)\n",
    "        \n",
    "        try:\n",
    "            path = os.path.join(os.getenv(\"EXTRACTED_SKILLS\"),f\"\"\"extracted_skills_{job_id}.json\"\"\")\n",
    "            with open(path, \"a\",  encoding='utf-8') as file:\n",
    "                json.dump(output_dict,   file, ensure_ascii=False)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d078980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    \\n     try:\\n        path = os.path.join(os.getenv(\"EXTRACTED_SKILLS\"),f\"\"\"extracted_skills_{job_id}.json\"\"\")\\n        with open(path, \"a\",  encoding=\\'utf-8\\') as file:\\n           json.dump(output_dict,   file, ensure_ascii=False)\\n    except Exception as e:\\n    pass\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def refine_skills(initial_skill, vector_matches, prompt_template_fname, jobid, llm):\n",
    "\n",
    "    \"\"\"\n",
    "    Refine extracted skills\n",
    "    \"\"\"\n",
    "    #first fetch the top n most similar jobs for the skill\n",
    "    \n",
    "    response_schemas = []\n",
    "    schema =  ResponseSchema(name=f\"\"\"Refined Skills\"\"\",\n",
    "                             description=f\"\"\"The refined skills from the top 10 after your review in a python list of strings\"\"\"\n",
    "                             )\n",
    "\n",
    "    response_schemas.append(schema)\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "    \n",
    "    \n",
    "\n",
    "    prompt_path = os.path.join(os.getenv(\"PROMPTS\"),prompt_template_fname)\n",
    "    with open(prompt_path,\"r\") as file:\n",
    "        template_string = file.read()\n",
    "    prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "\n",
    "    message = prompt_template.format_messages(\n",
    "        client_skill=initial_skill,\n",
    "        preliminary_matches=vector_matches,\n",
    "        format_instructions=format_instructions\n",
    "        )\n",
    "\n",
    "    response = llm(message)\n",
    "    output_dict = output_parser.parse(response.content)\n",
    "    output_dict[\"id\"] = jobid\n",
    "    output_dict[\"query_skill\"] = initial_skill\n",
    "    \n",
    "    return output_dict\n",
    "'''\n",
    "    \n",
    "     try:\n",
    "        path = os.path.join(os.getenv(\"EXTRACTED_SKILLS\"),f\"\"\"extracted_skills_{job_id}.json\"\"\")\n",
    "        with open(path, \"a\",  encoding='utf-8') as file:\n",
    "           json.dump(output_dict,   file, ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "    pass\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fdf36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_job_descriptions():\n",
    "\n",
    "    jd_path = os.getenv(\"JOB_DESCRIPTIONS\")\n",
    "    jd_files = os.listdir(jd_path)\n",
    "    to_extract = []\n",
    "    for jd_file in tqdm(jd_files):\n",
    "        with open(os.path.join(jd_path,jd_file), 'r') as file:\n",
    "            data = json.load(file)\n",
    "            for item in data:\n",
    "                to_extract.append({\"id\":item[\"id\"],\n",
    "                                   \"positionName\":item[\"positionName\"],\n",
    "                                   \"description\":item[\"description\"]})\n",
    "            \n",
    "    \n",
    "    return to_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e32a71-c22e-494f-ba02-538b8d25f81b",
   "metadata": {},
   "source": [
    "## Generate skill assesments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1806c089-9721-4e7c-afc6-c64470ce1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = os.getenv(\"LLM_URL\")\n",
    "#model = \"gpt-3.5-turbo\"\n",
    "#model = \"gpt-4-turbo-preview\"\n",
    "#llm = ChatOpenAI(temperature=temperature, model=accepted_answer_model)\n",
    "scale = 10\n",
    "temperature = 0.2\n",
    "max_tokens=512\n",
    "random_seed = 1\n",
    "prompt_template_fname = \"assess_skill_for_job.txt\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        base_url=os.getenv(\"LLM_URL\"),\n",
    "        api_key=\"not-needed\",\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        model_kwargs={\"seed\": random_seed}\n",
    "        )\n",
    "\n",
    "generate_assesment(\"C++\", scale, prompt_template_fname, llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5cb0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "850176d8",
   "metadata": {},
   "source": [
    "## Extract skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be5d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = os.getenv(\"LLM_URL\")\n",
    "\n",
    "temperature = 0.2\n",
    "max_tokens=1024\n",
    "random_seed = 1\n",
    "prompt_template_fname = \"extract_skills_from_job_description.txt\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        base_url=os.getenv(\"LLM_URL\"),\n",
    "        api_key=\"not-needed\",\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        model_kwargs={\"seed\": random_seed}\n",
    "        )\n",
    "jobs = load_job_descriptions()\n",
    "extract_skills(jobs, prompt_template_fname, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e107b42",
   "metadata": {},
   "source": [
    "## Map Extracted skills to Lightcast with refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b841796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_extracted_skills_to_lc_refine():\n",
    "\n",
    "    set_debug(False)\n",
    "    \n",
    "    model_name = os.getenv(\"EMBEDDING_MODEL\")\n",
    "    model = SentenceTransformer(model_name,device=get_device())\n",
    "    top_k = 10\n",
    "    temperature = 0.2\n",
    "    max_tokens=1024\n",
    "    random_seed=1\n",
    "    \n",
    "    prompt_template_fname = \"refine_extracted_skills.txt\"\n",
    "    \n",
    "    llm = ChatOpenAI(\n",
    "        base_url=os.getenv(\"LLM_URL\"),\n",
    "        api_key=\"not-needed\",\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        model_kwargs={\"seed\": random_seed}\n",
    "        )\n",
    "\n",
    "    data_path = os.getenv(\"EXTRACTED_SKILLS\")\n",
    "    files = [f for f in os.listdir(data_path) if f.endswith(\".json\")]\n",
    "\n",
    "    mapped_skills = []\n",
    "\n",
    "    output_data = []\n",
    "    for f in tqdm(files[:2]):\n",
    "        # each file is a job with initially extracted skills\n",
    "        with open(os.path.join(data_path,f), 'r') as data_file:\n",
    "\n",
    "            refined_skills = []\n",
    "            try:\n",
    "                data = json.load(data_file)\n",
    "                jobid = data[\"id\"]\n",
    "                print(f\"\"\"processing job {jobid}\"\"\")\n",
    "                for skill in data[\"Skills\"]:\n",
    "                    # do a vector search for the top_k most similar skilles to this skill\n",
    "                    top_skills = map_skills(skill, top_k, model, model_name, write_output=True)\n",
    "                    top_skills = pd.DataFrame(top_skills)\n",
    "                    top_skills[\"id\"] = jobid\n",
    "                    vector_matches = ','.join(list(top_skills[\"skill\"]))\n",
    "                    # refine the initial skill matches given the vector matches as context\n",
    "                    refined_skills.append(refine_skills(skill, vector_matches, prompt_template_fname, jobid, llm))\n",
    "                    mapped_skills.append(top_skills)\n",
    "        \n",
    "                #mapped_skills = pd.concat(mapped_skills)\n",
    "                refined_skills = pd.DataFrame(refined_skills)\n",
    "                matrix  = list(refined_skills['Refined Skills'])\n",
    "                refined_skills = [item for row in matrix for item in row]\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "        print(f\"\"\"refined skills for {jobid}\"\"\")\n",
    "        output_data.append({\"id\":jobid,\"refined_skills\":refined_skills})\n",
    "\n",
    "    output_data = pd.DataFrame(output_data)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40f07b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/vasilishatzopoulos/.cache/torch/sentence_transformers/WhereIsAI_UAE-Large-V1. Creating a new one with MEAN pooling.\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing job 6d70e9dd538a4c45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      " 50%|█████     | 1/2 [00:32<00:32, 32.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refined skills for 6d70e9dd538a4c45\n",
      "processing job 0a07b81587d36976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "100%|██████████| 2/2 [01:04<00:00, 32.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refined skills for 0a07b81587d36976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_data = map_extracted_skills_to_lc_refine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c17cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Data Science',\n",
       "  'Machine Learning',\n",
       "  'Big Data',\n",
       "  'Advanced Analytics',\n",
       "  'Microsoft Office',\n",
       "  'Telecommuting']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(output_data[output_data['id']=='0a07b81587d36976']['refined_skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f34a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
