{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if os.name == \"nt\":\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "    else:\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available else \"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Lightcast_catalogue(data_path):\n",
    "    with open(data_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vectors(Lightcast_data, model):\n",
    "    names = [datum[\"name\"] for datum in Lightcast_data]\n",
    "    vectors = model.encode(names,show_progress_bar=True)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(Lightcast_data, collection_name, model):\n",
    "\n",
    "    qdrant_client = QdrantClient(os.getenv(\"QDRANT_URL\"))\n",
    "\n",
    "    vectors = make_vectors(Lightcast_data, model)\n",
    "    qdrant_client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=model.get_sentence_embedding_dimension(),\n",
    "                                    distance=Distance.COSINE)\n",
    "    )\n",
    "\n",
    "    if \"skills\" in collection_name:\n",
    "        payload = [\n",
    "            {\n",
    "                \"name\":datum[\"name\"],\n",
    "                \"id\":datum[\"id\"],\n",
    "                \"infoUrl\":datum[\"infoUrl\"],\n",
    "            }\n",
    "            for datum in Lightcast_data \n",
    "        ]\n",
    "    elif \"jobs\" in collection_name:\n",
    "        payload = [\n",
    "            {\n",
    "                \"name\":datum[\"name\"],\n",
    "                \"id\":datum[\"id\"],\n",
    "            }\n",
    "            for datum in Lightcast_data \n",
    "        ]\n",
    "\n",
    "    qdrant_client.upload_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors=vectors,\n",
    "        payload=payload,\n",
    "        ids=None,\n",
    "        batch_size=1024\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(os.getenv(\"EMBEDDING_MODEL\"),device=get_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize skills and jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(skills=True, jobs=False):\n",
    "    if skills:\n",
    "        data_path = os.getenv(\"DATA_SKILLS\")\n",
    "        print(\"Vectorizing skills\")\n",
    "        skills = read_Lightcast_catalogue(data_path)[\"data\"]\n",
    "        model_name = os.getenv(\"EMBEDDING_MODEL\").split('/')[1]\n",
    "        collection_name = '_'.join([data_path.split('/')[-1].split('.')[0],model_name])\n",
    "        print(f\"\"\"Vectorizing skills to collection {collection_name}\"\"\")\n",
    "        vectorize_data(skills, collection_name, model)\n",
    "    \n",
    "    if jobs:\n",
    "        print(\"Vectorizing jobs\")\n",
    "        data_path = os.getenv(\"DATA_JOBS\")\n",
    "        jobs = read_Lightcast_catalogue(data_path)[\"data\"]\n",
    "        model_name = os.getenv(\"EMBEDDING_MODEL\").split('/')[1]\n",
    "        collection_name = '_'.join([data_path.split('/')[-1].split('.')[0],model_name])\n",
    "        print(f\"\"\"Vectorizing jobs to collection {collection_name}\"\"\")\n",
    "        vectorize_data(jobs, collection_name, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(skills=True, jobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
